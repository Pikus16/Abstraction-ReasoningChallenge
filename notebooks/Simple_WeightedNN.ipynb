{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes a simple neural network and applies it to the given problem. The only semi-involved part is that the losses are weighted so the background is less considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from arc_code.data import get_data\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "#import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the data\n",
    "X_train, Y_train, X_test, Y_test = get_data('../data', training_set = True, grouped_by_problem = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(grid, shape_to_pad_to, fill = -1):\n",
    "    # pads the grid to be of shape <shape_to_pad_to> with\n",
    "    # fill values <fill>\n",
    "    x_resize, y_resize = (shape_to_pad_to - grid.shape )/2.0\n",
    "    \n",
    "    def transform_format(arr):\n",
    "        if arr%1 != 0:\n",
    "            arr = [math.floor(arr),math.ceil(arr)]\n",
    "        else:\n",
    "            arr = [int(arr), int(arr)]\n",
    "        return arr\n",
    "    \n",
    "    x_resize, y_resize = transform_format(x_resize), transform_format(y_resize)\n",
    "    padded = np.pad(grid,[x_resize,y_resize,], 'constant', constant_values=fill)\n",
    "    # add last layer\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data, resize_shape, resize_method = 'pad', fill = 10):\n",
    "    new_data = np.zeros((len(data),resize_shape[0], resize_shape[1], 1), dtype = np.float32)\n",
    "    for i,x in enumerate(data):\n",
    "        if resize_method == 'pad':\n",
    "            x = pad(x, resize_shape, fill = fill)\n",
    "        else:\n",
    "            x = np.array(Image.fromarray(x.astype(np.uint8)).resize((30,30),0))\n",
    "        new_data[i] = (x[:,:,np.newaxis]).astype(np.float32)\n",
    "  \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_layer_flat_model(num_classes, flattened_shape):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=np.append(flattened_shape,1)),\n",
    "        #keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(num_classes)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_layer(input_shape, num_classes = 11, filters = 3, kernel_size = 3,\n",
    "              stride = 1, kernel_regularizer = None,\n",
    "             activity_regularizer = None, bias_regularizer = None, dilation = 1):\n",
    "    # assume input shape == outputshape\n",
    "    #upsample_kernel_size = output_shape - ((input_shape - 1) * stride\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(\n",
    "            filters = filters,\n",
    "            kernel_size = kernel_size,\n",
    "            strides= stride,\n",
    "            padding=\"valid\",\n",
    "            activation='relu',\n",
    "            kernel_regularizer = kernel_regularizer,\n",
    "            activity_regularizer = activity_regularizer,\n",
    "            bias_regularizer = bias_regularizer,\n",
    "            input_shape=np.append(input_shape,1)),\n",
    "        tf.keras.layers.Conv2DTranspose(\n",
    "            filters = num_classes,\n",
    "            kernel_size = kernel_size,\n",
    "            strides= stride,\n",
    "            padding=\"valid\",\n",
    "            output_padding=None,\n",
    "            data_format=None,\n",
    "            dilation_rate=dilation,\n",
    "            activation=\"relu\",\n",
    "            use_bias=True,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "            bias_regularizer=bias_regularizer,\n",
    "            activity_regularizer=activity_regularizer)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tf.constant(np.random.randint(0, 5, 6), dtype=tf.int32)\n",
    "\n",
    "# specify some class weightings\n",
    "class_weights = tf.constant([0.3, 0.1, 0.2, 0.3, 0.1])\n",
    "\n",
    "# specify the weights for each sample in the batch (without having to compute the onehot label matrix)\n",
    "weights = tf.gather(class_weights, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 3, 1, 0], dtype=int32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1, 0.1, 0.3, 0.3, 0.1, 0.3], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_loss(y_true, y_pred):\n",
    "    # your class weights\n",
    "    class_weights = tf.convert_to_tensor(np.append(np.repeat(1.0, 10),0.1), dtype = y_true.dtype)\n",
    "    # deduce weights for batch samples based on their true label\n",
    "    weights = tf.reduce_sum(class_weights * y_true, axis=1)\n",
    "    # compute your (unweighted) softmax cross entropy loss\n",
    "    unweighted_losses = tf.nn.softmax_cross_entropy_with_logits(y_true, y_pred)\n",
    "    # apply the weights, relying on broadcasting of the multiplication\n",
    "    print(class_weights.shape, y_true.shape, y_pred.shape, weights.shape,unweighted_losses.shape)\n",
    "    weighted_losses = unweighted_losses * weights\n",
    "    # reduce the result to get your final loss\n",
    "    loss = tf.reduce_mean(weighted_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_loss(y_true, y_pred):\n",
    "        w = tf.reduce_sum(y_true)/tf.cast(tf.size(y_true), tf.float32)\n",
    "        loss = w * tf.nn.softmax_cross_entropy_with_logits(y_true, y_pred)\n",
    "        return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(model_func, X_train, Y_train, X_test, Y_test, num_epochs = 50,\n",
    "         resize_shape = np.array((30,30)), resize_method = 'pad', fill = 10, *args):\n",
    "    \n",
    "    X_train = process_data(X_train, resize_shape = resize_shape, resize_method = resize_method, fill = fill)\n",
    "    Y_train = process_data(Y_train, resize_shape = resize_shape, resize_method = resize_method, fill = fill)\n",
    "    X_test = process_data(X_test, resize_shape = resize_shape, resize_method = resize_method, fill = fill)\n",
    "    Y_test = process_data(Y_test, resize_shape = resize_shape, resize_method = resize_method, fill = fill)\n",
    "    \n",
    "    model = model_func(input_shape = resize_shape, *args)\n",
    "    model.compile(optimizer='adam',\n",
    "              loss=weighted_loss,#tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    model.fit(X_train, Y_train, epochs=num_epochs, validation_data = (X_test, Y_test))\n",
    "    test_loss, test_acc = model.evaluate(X_test,  Y_test, verbose=2)\n",
    "    return model, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1301 samples, validate on 416 samples\n",
      "Epoch 1/10\n",
      "1301/1301 [==============================] - 4s 3ms/sample - loss: 145.1384 - accuracy: 0.0347 - val_loss: 167.7167 - val_accuracy: 0.0416\n",
      "Epoch 2/10\n",
      "1301/1301 [==============================] - 3s 2ms/sample - loss: 176.0631 - accuracy: 0.1048 - val_loss: 192.7043 - val_accuracy: 0.1130\n",
      "Epoch 3/10\n",
      "1301/1301 [==============================] - 3s 2ms/sample - loss: 197.5781 - accuracy: 0.1721 - val_loss: 221.1086 - val_accuracy: 0.4206\n",
      "Epoch 4/10\n",
      "1301/1301 [==============================] - 3s 2ms/sample - loss: 239.6323 - accuracy: 0.4879 - val_loss: 279.7017 - val_accuracy: 0.5038\n",
      "Epoch 5/10\n",
      "1301/1301 [==============================] - 4s 3ms/sample - loss: 305.4075 - accuracy: 0.5336 - val_loss: 346.9369 - val_accuracy: 0.5349\n",
      "Epoch 6/10\n",
      "1301/1301 [==============================] - 4s 3ms/sample - loss: 368.0255 - accuracy: 0.5512 - val_loss: 413.9532 - val_accuracy: 0.5453\n",
      "Epoch 7/10\n",
      "1301/1301 [==============================] - 3s 2ms/sample - loss: 436.1246 - accuracy: 0.5573 - val_loss: 478.5551 - val_accuracy: 0.5492\n",
      "Epoch 8/10\n",
      "1301/1301 [==============================] - 3s 3ms/sample - loss: 503.6907 - accuracy: 0.5588 - val_loss: 543.5344 - val_accuracy: 0.5488\n",
      "Epoch 9/10\n",
      "1301/1301 [==============================] - 3s 3ms/sample - loss: 567.3498 - accuracy: 0.5598 - val_loss: 607.1684 - val_accuracy: 0.5495\n",
      "Epoch 10/10\n",
      "1301/1301 [==============================] - 4s 3ms/sample - loss: 626.9257 - accuracy: 0.5599 - val_loss: 667.7638 - val_accuracy: 0.5498\n",
      "416/416 - 0s - loss: 667.7638 - accuracy: 0.5498\n"
     ]
    }
   ],
   "source": [
    "model, X_test_proc, Y_test_proc = run(one_layer, X_train, Y_train, X_test, Y_test, num_epochs = 10, resize_method = 'resize')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the problem with the best accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = 0\n",
    "which_best = -1\n",
    "for i,x in enumerate(X_test_proc):\n",
    "    test_loss, test_acc = model.evaluate(X_test_proc[i:i+1],  Y_test_proc[i:i+1], verbose=0)\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "        which_best = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc87359fe10>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, ax = plt.subplots(1,3)\n",
    "ax[0].imshow(X_test[which_best])\n",
    "ax[1].imshow(Y_test[which_best])\n",
    "ax[2].imshow(np.argmax(model(X_test_proc[which_best:which_best+1]).numpy(), axis = 3)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:arc] *",
   "language": "python",
   "name": "conda-env-arc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
